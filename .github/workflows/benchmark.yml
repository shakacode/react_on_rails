name: Benchmark Workflow

on:
  workflow_dispatch:
    inputs:
      routes:
        description: 'Comma-separated routes to benchmark (e.g., "/,/hello"). Leave empty to auto-detect from Rails.'
        required: false
        type: string
      rate:
        description: 'Requests per second (use "max" for maximum throughput)'
        required: false
        default: 'max'
        type: string
      duration:
        description: 'Duration (e.g., "30s", "1m", "90s")'
        required: false
        default: '30s'
        type: string
      request_timeout:
        description: 'Request timeout (e.g., "60s", "1m", "90s")'
        required: false
        default: '60s'
        type: string
      connections:
        description: 'Concurrent connections/virtual users (also used as max)'
        required: false
        default: 10
        type: number
      web_concurrency:
        description: 'Number of Puma worker processes'
        required: false
        default: 4
        type: number
      rails_threads:
        description: 'Number of Puma threads (min and max will be same)'
        required: false
        default: 3
        type: number
      app_version:
        description: 'Which app version to benchmark'
        required: false
        default: 'both'
        type: choice
        options:
          - 'both'
          - 'core_only'
          - 'pro_only'
          - 'pro_rails_only'
          - 'pro_node_renderer_only'
  push:
    branches:
      - master
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    types: [opened, synchronize, reopened, labeled]
    paths-ignore:
      - '**.md'
      - 'docs/**'
env:
  RUBY_VERSION: '3.3.7'
  BUNDLER_VERSION: '2.5.4'
  K6_VERSION: '1.4.2'
  VEGETA_VERSION: '12.13.0'
  # Determine which apps/benchmarks to run (default is 'both' for all triggers)
  RUN_CORE: ${{ contains(fromJSON('["both", "core_only"]'), github.event.inputs.app_version || 'both') && 'true' || '' }}
  RUN_PRO: ${{ (github.event.inputs.app_version || 'both') != 'core_only' && 'true' || '' }}
  RUN_PRO_RAILS: ${{ contains(fromJSON('["both", "pro_only", "pro_rails_only"]'), github.event.inputs.app_version || 'both') && 'true' || '' }}
  RUN_PRO_NODE_RENDERER: ${{ contains(fromJSON('["both", "pro_only", "pro_node_renderer_only"]'), github.event.inputs.app_version || 'both') && 'true' || '' }}
  # Benchmark parameters (defaults in bench.rb unless overridden here for CI)
  ROUTES: ${{ github.event.inputs.routes }}
  RATE: ${{ github.event.inputs.rate || 'max' }}
  DURATION: ${{ github.event.inputs.duration }}
  REQUEST_TIMEOUT: ${{ github.event.inputs.request_timeout }}
  CONNECTIONS: ${{ github.event.inputs.connections }}
  MAX_CONNECTIONS: ${{ github.event.inputs.connections }}
  WEB_CONCURRENCY: ${{ github.event.inputs.web_concurrency || 4 }}
  RAILS_MAX_THREADS: ${{ github.event.inputs.rails_threads || 3 }}
  RAILS_MIN_THREADS: ${{ github.event.inputs.rails_threads || 3 }}

jobs:
  benchmark:
    # Run on: push to master, workflow_dispatch, or PRs with 'full-ci' or 'benchmark' labels
    if: |
      github.event_name == 'push' ||
      github.event_name == 'workflow_dispatch' ||
      contains(github.event.pull_request.labels.*.name, 'full-ci') ||
      contains(github.event.pull_request.labels.*.name, 'benchmark')
    runs-on: ubuntu-latest
    env:
      SECRET_KEY_BASE: 'dummy-secret-key-for-ci-testing-not-used-in-production'
      REACT_ON_RAILS_PRO_LICENSE: ${{ secrets.REACT_ON_RAILS_PRO_LICENSE_V2 }}

    steps:
      # ============================================
      # STEP 1: CHECKOUT CODE
      # ============================================
      - name: Checkout repository
        uses: actions/checkout@v4

      # ============================================
      # STEP 2: INSTALL BENCHMARKING TOOLS
      # ============================================

      - name: Add tools directory to PATH
        run: |
          mkdir -p ~/bin
          echo "$HOME/bin" >> $GITHUB_PATH

      - name: Cache Vegeta binary
        id: cache-vegeta
        if: env.RUN_PRO
        uses: actions/cache@v4
        with:
          path: ~/bin/vegeta
          key: vegeta-${{ runner.os }}-${{ runner.arch }}-${{ env.VEGETA_VERSION }}

      - name: Install Vegeta
        if: env.RUN_PRO && steps.cache-vegeta.outputs.cache-hit != 'true'
        run: |
          echo "üì¶ Installing Vegeta v${VEGETA_VERSION}"

          # Download and extract vegeta binary
          wget -q https://github.com/tsenart/vegeta/releases/download/v${VEGETA_VERSION}/vegeta_${VEGETA_VERSION}_linux_amd64.tar.gz
          tar -xzf vegeta_${VEGETA_VERSION}_linux_amd64.tar.gz

          # Store in cache directory
          mv vegeta ~/bin/

      - name: Setup k6
        uses: grafana/setup-k6-action@v1
        with:
          k6-version: ${{ env.K6_VERSION }}

      # ============================================
      # STEP 3: START APPLICATION SERVER
      # ============================================

      - name: Setup Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: ${{ env.RUBY_VERSION }}
          bundler: ${{ env.BUNDLER_VERSION }}

      - name: Get gem home directory
        run: echo "GEM_HOME_PATH=$(gem env home)" >> $GITHUB_ENV

      - name: Cache foreman gem
        id: cache-foreman
        uses: actions/cache@v4
        with:
          path: ${{ env.GEM_HOME_PATH }}
          key: foreman-gem-${{ runner.os }}-ruby-${{ env.RUBY_VERSION }}

      - name: Install foreman
        if: steps.cache-foreman.outputs.cache-hit != 'true'
        run: gem install foreman

      - name: Fix dependency for libyaml-dev
        run: sudo apt install libyaml-dev -y

      # Follow https://github.com/pnpm/action-setup?tab=readme-ov-file#use-cache-to-reduce-installation-time
      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          cache: true
          cache_dependency_path: '**/pnpm-lock.yaml'
          run_install: false

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Print system information
        run: |
          echo "Linux release: "; cat /etc/issue
          echo "Current user: "; whoami
          echo "Current directory: "; pwd
          echo "Ruby version: "; ruby -v
          echo "Node version: "; node -v
          echo "Pnpm version: "; pnpm --version
          echo "Bundler version: "; bundle --version

      - name: Install Node modules with Pnpm for all packages
        run: |
          pnpm install --recursive --frozen-lockfile
          pnpm add --global yalc

      - name: yalc publish for react-on-rails
        run: cd packages/react-on-rails && yalc publish

      - name: Cache core dummy app node modules
        if: env.RUN_CORE
        uses: actions/cache@v4
        with:
          path: react_on_rails/spec/dummy/node_modules
          key: v4-core-dummy-app-node-modules-cache-${{ hashFiles('react_on_rails/spec/dummy/pnpm-lock.yaml') }}

      - name: Install Node modules for the dummy app
        if: env.RUN_CORE
        run: |
          cd react_on_rails/spec/dummy
          yalc add --link react-on-rails
          pnpm install

      - name: Save Core dummy app ruby gems to cache
        if: env.RUN_CORE
        uses: actions/cache@v4
        with:
          path: react_on_rails/spec/dummy/vendor/bundle
          key: v4-core-dummy-app-gem-cache-${{ hashFiles('react_on_rails/spec/dummy/Gemfile.lock') }}

      - name: Install Ruby Gems for Core dummy app
        if: env.RUN_CORE
        run: |
          cd react_on_rails/spec/dummy
          bundle config set path vendor/bundle
          bundle config set frozen true
          bundle _${BUNDLER_VERSION}_ install --jobs=4 --retry=3

      - name: Prepare Core production assets
        if: env.RUN_CORE
        run: |
          set -e  # Exit on any error
          echo "üî® Building production assets..."
          cd react_on_rails/spec/dummy

          if ! bin/prod-assets; then
            echo "‚ùå ERROR: Failed to build production assets"
            exit 1
          fi

          echo "‚úÖ Production assets built successfully"

      - name: Start Core production server
        if: env.RUN_CORE
        run: |
          set -e  # Exit on any error
          echo "üöÄ Starting production server..."
          cd react_on_rails/spec/dummy

          # Start server in background (Core uses rails directly, not foreman)
          bin/prod &
          echo "Server started in background"

          # Wait for server to be ready (max 30 seconds)
          echo "‚è≥ Waiting for server to be ready..."
          for i in {1..30}; do
            if curl -fsS http://localhost:3001 > /dev/null; then
              echo "‚úÖ Server is ready and responding"
              exit 0
            fi
            echo "  Attempt $i/30: Server not ready yet..."
            sleep 1
          done

          echo "‚ùå ERROR: Server failed to start within 30 seconds"
          exit 1

      # ============================================
      # STEP 4: RUN CORE BENCHMARKS
      # ============================================

      - name: Execute Core benchmark suite
        if: env.RUN_CORE
        timeout-minutes: 120
        run: |
          set -e  # Exit on any error
          echo "üèÉ Running Core benchmark suite..."

          if ! ruby benchmarks/bench.rb; then
            echo "‚ùå ERROR: Benchmark execution failed"
            exit 1
          fi

          echo "‚úÖ Benchmark suite completed successfully"

      - name: Validate Core benchmark results
        if: env.RUN_CORE
        run: |
          set -e
          echo "üîç Validating benchmark results..."

          if [ ! -f "bench_results/summary.txt" ]; then
            echo "‚ùå ERROR: benchmark summary file not found"
            exit 1
          fi

          echo "‚úÖ Benchmark results found"
          echo ""
          echo "üìä Summary:"
          column -t -s $'\t' bench_results/summary.txt
          echo ""
          echo "Generated files:"
          ls -lh bench_results/

      - name: Convert Core benchmark results to JSON
        if: env.RUN_CORE
        run: |
          ruby benchmarks/convert_to_benchmark_json.rb "Core: "

      - name: Store Core RPS benchmark results
        if: env.RUN_CORE
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Core Benchmark - RPS
          tool: customBiggerIsBetter
          output-file-path: bench_results/benchmark_rps.json
          gh-pages-branch: benchmark-data
          benchmark-data-dir-path: docs/benchmarks
          alert-threshold: '150%'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          comment-on-alert: true
          alert-comment-cc-users: '@alexeyr-ci2'
          fail-on-alert: true
          summary-always: true
          auto-push: false

      - name: Store Core latency benchmark results
        if: env.RUN_CORE
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Core Benchmark - Latency
          tool: customSmallerIsBetter
          output-file-path: bench_results/benchmark_latency.json
          gh-pages-branch: benchmark-data
          benchmark-data-dir-path: docs/benchmarks
          alert-threshold: '150%'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          comment-on-alert: true
          alert-comment-cc-users: '@alexeyr-ci2'
          fail-on-alert: true
          summary-always: true
          auto-push: false

      - name: Upload Core benchmark results
        uses: actions/upload-artifact@v4
        if: env.RUN_CORE && always()
        with:
          name: benchmark-core-results-${{ github.run_number }}
          path: bench_results/
          retention-days: 30
          if-no-files-found: warn

      - name: Stop Core production server
        if: env.RUN_CORE && always()
        run: |
          echo "üõë Stopping Core production server..."
          # Kill all server-related processes (safe in isolated CI environment)
          pkill -9 -f "ruby|node|foreman|overmind|puma" || true

          # Wait for port 3001 to be free
          echo "‚è≥ Waiting for port 3001 to be free..."
          for _ in {1..10}; do
            if ! lsof -ti:3001 > /dev/null 2>&1; then
              echo "‚úÖ Port 3001 is now free"
              exit 0
            fi
            sleep 1
          done

          echo "‚ùå ERROR: Port 3001 is still in use after 10 seconds"
          echo "Processes using port 3001:"
          lsof -i:3001 || true
          exit 1

      # ============================================
      # STEP 5: SETUP PRO APPLICATION SERVER
      # ============================================
      - name: Cache Pro dummy app node modules
        if: env.RUN_PRO
        uses: actions/cache@v4
        with:
          path: react_on_rails_pro/spec/dummy/node_modules
          key: v4-pro-dummy-app-node-modules-cache-${{ hashFiles('react_on_rails_pro/spec/dummy/pnpm-lock.yaml') }}

      - name: yalc publish for react-on-rails-pro
        if: env.RUN_PRO
        run: cd packages/react-on-rails-pro && yalc publish

      - name: Install Node modules with Pnpm for Pro dummy app
        if: env.RUN_PRO
        run: |
          cd react_on_rails_pro/spec/dummy
          yalc add --link react-on-rails-pro
          pnpm install

      - name: Cache Pro dummy app Ruby gems
        if: env.RUN_PRO
        uses: actions/cache@v4
        with:
          path: react_on_rails_pro/spec/dummy/vendor/bundle
          key: v4-pro-dummy-app-gem-cache-${{ hashFiles('react_on_rails_pro/spec/dummy/Gemfile.lock') }}

      - name: Install Ruby Gems for Pro dummy app
        if: env.RUN_PRO
        run: |
          cd react_on_rails_pro/spec/dummy
          bundle config set path vendor/bundle
          bundle config set frozen true
          bundle _${BUNDLER_VERSION}_ install --jobs=4 --retry=3

      - name: Generate file-system based entrypoints for Pro
        if: env.RUN_PRO
        run: cd react_on_rails_pro/spec/dummy && bundle exec rake react_on_rails:generate_packs

      - name: Prepare Pro production assets
        if: env.RUN_PRO
        run: |
          set -e
          echo "üî® Building Pro production assets..."
          cd react_on_rails_pro/spec/dummy

          if ! bin/prod-assets; then
            echo "‚ùå ERROR: Failed to build production assets"
            exit 1
          fi

          echo "‚úÖ Production assets built successfully"

      - name: Start Pro production server
        if: env.RUN_PRO
        run: |
          set -e
          echo "üöÄ Starting Pro production server..."
          cd react_on_rails_pro/spec/dummy

          # Start server in background
          bin/prod &
          echo "Server started in background"

          # Wait for server to be ready (max 30 seconds)
          echo "‚è≥ Waiting for server to be ready..."
          for i in {1..30}; do
            if curl -fsS http://localhost:3001 > /dev/null; then
              echo "‚úÖ Server is ready and responding"
              exit 0
            fi
            echo "  Attempt $i/30: Server not ready yet..."
            sleep 1
          done

          echo "‚ùå ERROR: Server failed to start within 30 seconds"
          exit 1

      # ============================================
      # STEP 6: RUN PRO BENCHMARKS
      # ============================================

      - name: Execute Pro benchmark suite
        if: env.RUN_PRO_RAILS
        timeout-minutes: 120
        run: |
          set -e
          echo "üèÉ Running Pro benchmark suite..."

          if ! PRO=true ruby benchmarks/bench.rb; then
            echo "‚ùå ERROR: Benchmark execution failed"
            exit 1
          fi

          echo "‚úÖ Benchmark suite completed successfully"

      - name: Execute Pro Node Renderer benchmark suite
        if: env.RUN_PRO_NODE_RENDERER
        timeout-minutes: 30
        run: |
          set -e
          echo "üèÉ Running Pro Node Renderer benchmark suite..."

          if ! ruby benchmarks/bench-node-renderer.rb; then
            echo "‚ùå ERROR: Node Renderer benchmark execution failed"
            exit 1
          fi

          echo "‚úÖ Node Renderer benchmark suite completed successfully"

      - name: Validate Pro benchmark results
        if: env.RUN_PRO
        run: |
          set -e
          echo "üîç Validating benchmark results..."

          if [ "$RUN_PRO_RAILS" = "true" ]; then
            if [ ! -f "bench_results/summary.txt" ]; then
              echo "‚ùå ERROR: Rails benchmark summary file not found"
              exit 1
            fi
            echo "üìä Rails Benchmark Summary:"
            column -t -s $'\t' bench_results/summary.txt
            echo ""
          fi

          if [ "$RUN_PRO_NODE_RENDERER" = "true" ]; then
            if [ ! -f "bench_results/node_renderer_summary.txt" ]; then
              echo "‚ùå ERROR: Node Renderer benchmark summary file not found"
              exit 1
            fi
            echo "üìä Node Renderer Benchmark Summary:"
            column -t -s $'\t' bench_results/node_renderer_summary.txt
            echo ""
          fi

          echo "‚úÖ Benchmark results validated"
          echo ""
          echo "Generated files:"
          ls -lh bench_results/

      - name: Convert Pro benchmark results to JSON
        if: env.RUN_PRO
        run: |
          ruby benchmarks/convert_to_benchmark_json.rb "Pro: "

      - name: Store Pro RPS benchmark results
        if: env.RUN_PRO
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Pro Benchmark - RPS
          tool: customBiggerIsBetter
          output-file-path: bench_results/benchmark_rps.json
          gh-pages-branch: benchmark-data
          benchmark-data-dir-path: docs/benchmarks
          alert-threshold: '150%'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          comment-on-alert: true
          alert-comment-cc-users: '@alexeyr-ci2'
          fail-on-alert: true
          summary-always: true
          auto-push: false

      - name: Store Pro latency benchmark results
        if: env.RUN_PRO
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Pro Benchmark - Latency
          tool: customSmallerIsBetter
          output-file-path: bench_results/benchmark_latency.json
          gh-pages-branch: benchmark-data
          benchmark-data-dir-path: docs/benchmarks
          alert-threshold: '150%'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          comment-on-alert: true
          alert-comment-cc-users: '@alexeyr-ci2'
          fail-on-alert: true
          summary-always: true
          auto-push: false

      - name: Upload Pro benchmark results
        uses: actions/upload-artifact@v4
        if: env.RUN_PRO && always()
        with:
          name: benchmark-pro-results-${{ github.run_number }}
          path: bench_results/
          retention-days: 30
          if-no-files-found: warn

      - name: Stop Pro production server
        if: env.RUN_PRO && always()
        run: |
          echo "üõë Stopping Pro production server..."
          # Kill all server-related processes (safe in isolated CI environment)
          pkill -9 -f "ruby|node|foreman|overmind|puma" || true
          echo "‚úÖ Server stopped"

      # ============================================
      # STEP 7: PUSH BENCHMARK DATA
      # ============================================
      - name: Push benchmark data
        if: github.event_name == 'push' && github.ref == 'refs/heads/master'
        run: |
          git push 'https://github-actions:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git' benchmark-data:benchmark-data

      # ============================================
      # STEP 8: WORKFLOW COMPLETION
      # ============================================
      - name: Workflow summary
        if: always()
        run: |
          echo "üìã Benchmark Workflow Summary"
          echo "===================================="
          echo "Status: ${{ job.status }}"
          echo "Run number: ${{ github.run_number }}"
          echo "Triggered by: ${{ github.actor }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Run Core: ${{ env.RUN_CORE || 'false' }}"
          echo "Run Pro Rails: ${{ env.RUN_PRO_RAILS || 'false' }}"
          echo "Run Pro Node Renderer: ${{ env.RUN_PRO_NODE_RENDERER || 'false' }}"
          echo ""
          if [ "${{ job.status }}" == "success" ]; then
            echo "‚úÖ All steps completed successfully"
          else
            echo "‚ùå Workflow encountered errors - check logs above"
          fi
